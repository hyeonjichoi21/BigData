import requests
from bs4 import BeautifulSoup
import re
import time

# âœ… URLì—ì„œ ìƒí’ˆë²ˆí˜¸ ì¶”ì¶œ
def extract_goods_no_from_url(url):
    match = re.search(r'/goods/(\d+)', url, re.IGNORECASE)
    if match:
        return int(match.group(1))
    else:
        print("âŒ URLì—ì„œ ìƒí’ˆë²ˆí˜¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

# âœ… ë¦¬ë·° ë³¸ë¬¸ í¬ë¡¤ë§
def crawl_yes24_reviews(goods_no, max_pages=10):
    reviews = []
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": f"https://www.yes24.com/Product/Goods/{goods_no}",
        "X-Requested-With": "XMLHttpRequest",
    }

    for page in range(1, max_pages + 1):
        url = f"https://www.yes24.com/Product/communityModules/GoodsReviewList/{goods_no}?PageNumber={page}"
        res = requests.get(url, headers=headers)

        if res.status_code != 200:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {url}")
            continue

        soup = BeautifulSoup(res.text, "html.parser")
        review_tags = soup.select(".review_cont > p")

        if not review_tags:
            print(f"âš ï¸ {page}í˜ì´ì§€ì— ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        for tag in review_tags:
            text = tag.get_text(strip=True)
            if text:
                reviews.append(text)

        time.sleep(1)

    return reviews

# âœ… í‰ì (ë³„ì ) í¬ë¡¤ë§
def crawl_yes24_ratings(goods_no, max_pages=5):
    ratings = []
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": f"https://www.yes24.com/Product/Goods/{goods_no}",
        "X-Requested-With": "XMLHttpRequest",
    }

    for page in range(1, max_pages + 1):
        url = f"https://www.yes24.com/Product/communityModules/GoodsReviewList/{goods_no}?PageNumber={page}"
        res = requests.get(url, headers=headers)
        if res.status_code != 200:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {url}")
            continue

        soup = BeautifulSoup(res.text, "html.parser")
        rating_spans = soup.select("span.total_rating")

        if not rating_spans:
            print(f"âš ï¸ {page}í˜ì´ì§€ì— í‰ì  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        for span in rating_spans:
            text = span.get_text(strip=True)  # ì˜ˆ: "í‰ì 2ì "
            match = re.search(r"í‰ì (\d)ì ", text)
            if match:
                ratings.append(int(match.group(1)))

        time.sleep(1)

    return ratings

# âœ… ì»¬ëŸ¬ë§µ ì„ íƒ í•¨ìˆ˜
def get_colormap_by_rating(ratings):
    if not ratings:
        return "gray"
    avg = sum(ratings) / len(ratings)
    print(f"\nğŸ“Š í‰ê·  ë³„ì : {round(avg, 2)}ì ")
    if avg >= 8:
        return "Reds"
    elif avg >= 6:
        return "Oranges"
    else:
        return "Blues"




# âœ… ì‹¤í–‰ë¶€
book_url = input("YES24 ì±… ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
goods_no = extract_goods_no_from_url(book_url)

if goods_no:
    print(f"\n[ê²€ìƒ‰ëœ ìƒí’ˆ ë²ˆí˜¸: {goods_no}] ë¦¬ë·° ìˆ˜ì§‘ ì¤‘...\n")
    reviews = crawl_yes24_reviews(goods_no, max_pages=5)
    print(f"[YES24] ë¦¬ë·° {len(reviews)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ!\n")
    for i, review in enumerate(reviews[:5]):
        print(f"{i+1}. {review}")

    # âœ… ì „ì²˜ë¦¬
    from konlpy.tag import Okt
    import re

    stopwords = ['ì˜', 'ê°€', 'ì´', 'ì€', 'ë“¤', 'ëŠ”', 'ì¢€', 'ì˜', 'ê±', 'ê³¼', 'ë„', 'ë¥¼', 'ìœ¼ë¡œ', 'ì', 'ì—', 'ì™€', 'í•œ', 'í•˜ë‹¤']
    okt = Okt()

    def preprocess_reviews(reviews):
        processed = []
        for review in reviews:
            review = re.sub(r'[^ê°€-í£\s]', '', review)
            tokens = okt.nouns(review)  # ëª…ì‚¬ë§Œ ì¶”ì¶œ
            tokens = [word for word in tokens if word not in stopwords and len(word) > 1]
            processed.append(" ".join(tokens))
        return processed

    cleaned_reviews = preprocess_reviews(reviews)
    print(f"\n[ì „ì²˜ë¦¬ëœ ë¦¬ë·° ì˜ˆì‹œ]\n")
    for i, review in enumerate(cleaned_reviews[:5]):
        print(f"{i+1}. {review}")

    # ê°ì„± ë¶„ì„
    senti_dict = {
        "ì¢‹ë‹¤": 2, "ì¢‹ì•„": 2, "ìµœê³ ": 2, "ë§Œì¡±": 2, "ê°ë™": 2, "ì¶”ì²œ": 2, "ê°•ì¶”":4,
        "ì¬ë¯¸": 2, "ê¿€ì¼": 3, "ì¬ë°Œ": 2, "ëª…ì‘": 5, "ì¸ìƒì±…": 6,
        "ë³„ë¡œ": -3, "ì‹¤ë§": -3, "ì§€ë£¨": -3, "ë¹„ì¶”": -3, "ë¹„ì¶”ì²œ":-3, "ë¹„ì¶”ë‹¤": -3,
        "ìµœì•…": -4, "ë¶ˆë§Œ": -2, "ì•„ì‰½": -2, "ì•„ê¹": -2, "ì“°ë ˆê¸°": -5,
        "ë³„ì ": -1, "í›„íšŒ": -3, "ì§€ì €ë¶„": -3, "ë‚­ë¹„": -4
    }

    def get_sentiment_score(review):
        score = 0
        for word in review.split():
            score += senti_dict.get(word, 0)
        return score

    sentiment_results = [{"text": r, "score": get_sentiment_score(r)} for r in cleaned_reviews]

    print("\n[ê°ì„± ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ]")
    for i, item in enumerate(sentiment_results[:5]):
        label = "ê¸ì •" if item["score"] > 0 else "ë¶€ì •" if item["score"] < 0 else "ì¤‘ë¦½"
        print(f"{i+1}. ({label}) {item['text']}")

    # âœ… ê¸/ë¶€ì • ë¹„ìœ¨ ê³„ì‚°
    pos_cnt = sum(1 for r in sentiment_results if r["score"] > 0)
    neg_cnt = sum(1 for r in sentiment_results if r["score"] < 0)
    total_cnt = pos_cnt + neg_cnt if (pos_cnt + neg_cnt) > 0 else 1

    pos_ratio = pos_cnt / total_cnt
    neg_ratio = neg_cnt / total_cnt

    # âœ… 2. TF-IDF ë‹¨ì–´ ì¶”ì¶œ
    from sklearn.feature_extraction.text import TfidfVectorizer

    vectorizer = TfidfVectorizer(max_features=100)
    X = vectorizer.fit_transform(cleaned_reviews)

    tfidf_scores = dict(zip(vectorizer.get_feature_names_out(), X.sum(axis=0).tolist()[0]))

    top_keywords = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)[:20]
    print("\n[TF-IDF ìƒìœ„ í‚¤ì›Œë“œ]")
    for word, score in top_keywords:
        print(f"{word}: {round(score, 3)}")

    # âœ… matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm

    font_path = 'C:/Windows/Fonts/malgun.ttf'
    font_name = fm.FontProperties(fname=font_path).get_name()
    plt.rc('font', family=font_name)

    # âœ… 3. WordCloud ì‹œê°í™” (ê°ì„± ê¸°ë°˜ ì»¬ëŸ¬)
    from wordcloud import WordCloud

    colormap = "pink" if pos_ratio > neg_ratio else "Blues"

    wordcloud = WordCloud(
        font_path=font_path,
        background_color='white',
        width=800,
        height=400,
        colormap=colormap
    ).generate_from_frequencies(tfidf_scores)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(f" ê°ì„± ê¸°ë°˜ WordCloud ({'ê¸ì • ìš°ì„¸' if pos_ratio > neg_ratio else 'ë¶€ì • ìš°ì„¸'})")
    plt.show()

    # ê°ì •-ìƒ‰ìƒ ë§¤í•‘ ê¸°ë°˜ WordCloud
    emotion_color_map = {
        "ì‚¬ë‘": "pink", "ì—°ì• ": "lightpink", "ìš©ê¸°": "salmon", "ê³µê°": "lightcoral", "í–‰ë³µ": "gold",
        "í¬ë§": "orange", "ì´í•´": "lightskyblue", "ì„±ì¥": "lightgreen", "ì´ë³„": "skyblue", "ìš°ìš¸ì¦": "purple",
        "ìì‚´": "midnightblue", "í—ˆë¬´": "gray", "ë¯¸ì›€": "darkred", "ìƒì²˜": "indianred", "ê³ ë…": "dimgray",
        "ë¶ˆì•ˆ": "blue", "ì£½ìŒ": "black", "ìì‹ ": "teal", "ìì•„": "darkcyan", "ì² í•™ì": "slategray",
        "ì§ˆë¬¸": "steelblue", "ìƒê°": "deepskyblue", "ê¸°ì–µ": "mediumorchid", "ê¸°ë¡": "mediumslateblue",
        "ë§ê°": "darkslateblue", "ë‚´ë©´": "plum", "ì‚¬ëŒ": "lightgray", "ìš°ë¦¬": "lightsteelblue",
        "ì‚¬íšŒ": "darkolivegreen", "í˜„ì‹¤": "cadetblue", "ì‹œëŒ€": "sienna", "ê°€ì¡±": "khaki",
        "ì—¬ì„±": "orchid", "ì†Œì„¤": "burlywood", "ì‘ê°€": "wheat", "ë¬¸ì¥": "bisque", "ë¬¸ì²´": "antiquewhite",
        "ì´ì•¼ê¸°": "moccasin", "ê°ì •": "lightcoral", "ê°ì„±": "hotpink", "ê°ê°": "thistle",
        "ê´€ì ": "lightseagreen", "ì‹œì„ ": "aquamarine", "ê¸°ëŒ€": "peachpuff", "ì—­í• ": "rosybrown",
        "ëª¨ìŠµ": "tan", "ìˆœê°„": "lightsalmon", "ë³€í™”": "mediumaquamarine", "ì¸ìƒ": "palegreen",
        "ë‚´ìš©": "azure", "ì˜ë¯¸": "lightblue", "í˜ë¯¸ë‹ˆì¦˜": "purple"
    }

    def custom_color_func(word, font_size, position, orientation, font_path, random_state):
        return emotion_color_map.get(word, "gray")

    emotion_wordcloud = WordCloud(
        font_path=font_path,
        background_color='white',
        width=800,
        height=400,
        color_func=custom_color_func
    ).generate_from_frequencies(tfidf_scores)

    plt.figure(figsize=(10, 5))
    plt.imshow(emotion_wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(" ê°ì • ê¸°ë°˜ ìƒ‰ìƒ WordCloud")
    plt.show()
    
    
    # âœ… ì‹¤í–‰ í›„ ë¦¬ë·° ìˆ˜ì§‘ì´ ì™„ë£Œëœ ì´í›„, ì•„ë˜ ì½”ë“œ ì¶”ê°€

    # â­ï¸ ë³„ì  ê¸°ë°˜ WordCloud ì¶”ê°€
    ratings = crawl_yes24_ratings(goods_no, max_pages=5)
    print(f"\n[YES24] í‰ì  {len(ratings)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ!")
    print("â–¶ í‰ì  ì˜ˆì‹œ:", ratings[:10])

    colormap = get_colormap_by_rating(ratings)

    wordcloud_rating_based = WordCloud(
        font_path=font_path,
        background_color='white',
        width=800,
        height=400,
        colormap=colormap
    ).generate_from_frequencies(tfidf_scores)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud_rating_based, interpolation='bilinear')
    plt.axis('off')
    plt.title(f" ë³„ì  ê¸°ë°˜ WordCloud (ì»¬ëŸ¬: {colormap})")
    plt.show()

else:
    print("ì±… ë§í¬ê°€ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ìƒí’ˆë²ˆí˜¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")




# GoodsReviewList
# ì™œ ë‚˜ ë„ˆ ì‚¬ë‘: https://www.yes24.com/product/goods/115275383  O 
# í‘œë°±: https://www.yes24.com/product/goods/93375712
# ì•„ëª¬ë“œ: https://www.yes24.com/product/goods/37300128
# ë‚œì˜ê³µ: https://www.yes24.com/product/goods/125020220
# ë§ê°ì¼ê¸°: https://www.yes24.com/product/goods/115843545
# ë¯¸ì›€ë°›ì„ìš©ê¸°: https://www.yes24.com/product/goods/116599423 O 
# íŒŒê³¼: https://www.yes24.com/product/goods/125761518 <- ì–˜ë¡œ í…ŒìŠ¤íŠ¸í•˜ê¸°
# ì•„ê°€ë¯¸: https://www.yes24.com/product/goods/125761510 <- ì´ê±´ ê²°ê³¼ ã…‚ã„¹ì„ 
# ëª¨ìˆœ: https://www.yes24.com/product/goods/8759796
# ë‚˜ ì†Œë§ ë‚´ê²Œ ê¸ˆì§€: https://www.yes24.com/product/goods/72127217



